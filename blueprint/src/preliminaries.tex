\chapter{Preliminaries}

\section{Total Unimodularity}

\begin{definition}
    \label{Matrix}
    \leanok
    Matrix is a function that takes a row index and returns a vector, which is a function that takes a column index and returns a value.
    The former aforementioned identity is definitional, the latter is syntactical.
    By abuse of notation $\left(R^Y\right)^X \equiv R^{X \times Y}$ we do not curry functions in this text.
    When a matrix happens to be finite (that is, both $X$ and $Y$ are finite) and its entries are numeric, we like to represent it by a table of numbers.
\end{definition}

\begin{definition}
    \label{Matrix.det}
    \uses{Matrix}
    \leanok
    Let $A$ be a square matrix over a commutative ring whose rows and colummns are indexed by the integers $\{1, \dots, n\}$.
    The determinant of $A$ is
    \[
        \det A = \sum_{\sigma \in S_{n}} \left( \operatorname{sgn}(\sigma) \prod_{i = 1}^{n} a_{i, \sigma(i)} \right),
    \]
    where the sum is computed over all permutations $\sigma \in S_{n}$, $\operatorname{sgn}(\sigma)$ denotes the sign of permutation $\sigma$,
    and $a_{i,j} \in R$ is the element element of $A$ corresponding to the $i$-th row and the $j$-th column.
\end{definition}

\begin{definition}
    \label{Matrix.IsTotallyUnimodular}
    \uses{Matrix.det}
    % \lean{Matrix.IsTotallyUnimodular}
    \leanok
    Let $R$ be a commutative ring. We say that a matrix $A \in R^{X \times Y}$ is totally unimodular, or TU for short, if for every $k \in \mathbb{N}$, every (not necessarily contiguous) $k \times k$ submatrix $T$ of $A$ has $\det T \in \{0, \pm 1\}$.
\end{definition}

\begin{lemma}
    \label{Matrix.IsTotallyUnimodular.mul_rows}
    \uses{Matrix.IsTotallyUnimodular}
    % \lean{Matrix.IsTotallyUnimodular.mul_rows}
    \leanok
    Let $A$ be a TU matrix. Suppose rows of $A$ are multiplied by $\{0, \pm 1\}$ factors. Then the resulting matrix $A'$ is also TU.
\end{lemma}

\begin{proof}
    \uses{Matrix.IsTotallyUnimodular}
    % \lean{}
    \leanok
    We prove that $A'$ is TU by Definition~\ref{Matrix.IsTotallyUnimodular}. To this end, let $T'$ be a square submatrix of $A'$. Our goal is to show that $\det T' \in \{0, \pm 1\}$. Let $T$ be the submatrix of $A$ that represents $T'$ before pivoting. If some of the rows of $T$ were multiplied by zeros, then $T'$ contains zero rows, and hence $\det T' = 0$. Otherwise, $T'$ was obtained from $T$ by multiplying certain rows by $-1$. Since $T'$ has finitely many rows, the number of such multiplications is also finite. Since multiplying a row by $-1$ results in the determinant getting multiplied by $-1$, we get $\det T' = \pm \det T \in \{0, \pm 1\}$ as desired.
\end{proof}

\begin{lemma}
    \label{Matrix.IsTotallyUnimodular.mul_cols}
    \uses{Matrix.IsTotallyUnimodular}
    % \lean{Matrix.IsTotallyUnimodular.mul_cols}
    \leanok
    Let $A$ be a TU matrix. Suppose columns of $A$ are multiplied by $\{0, \pm 1\}$ factors. Then the resulting matrix $A'$ is also TU.
\end{lemma}

\begin{proof}
    \uses{Matrix.IsTotallyUnimodular,Matrix.IsTotallyUnimodular.mul_rows}
    % \lean{}
    \leanok
    Apply Lemma~\ref{Matrix.IsTotallyUnimodular.mul_rows} to $A^{\top}$.
\end{proof}

\begin{definition}
    \label{Matrix.IsPartiallyUnimodular}
    \uses{Matrix.det}
    % \lean{Matrix.IsPartiallyUnimodular}
    \leanok
    Given $k \in \mathbb{N}$, we say that a matrix $A$ is $k$-partially unimodular, or $k$-PU for short, if every (not necessarily contiguous, not necessarily injective) $k \times k$ submatrix $T$ of $A$ has $\det T \in \{0, \pm 1\}$.
\end{definition}

\begin{lemma}
    \label{Matrix.isTotallyUnimodular_iff_forall_isPartiallyUnimodular}
    \uses{Matrix.IsTotallyUnimodular,Matrix.IsPartiallyUnimodular}
    % \lean{Matrix.isTotallyUnimodular_iff_forall_isPartiallyUnimodular}
    \leanok
    A matrix $A$ is TU if and only if $A$ is $k$-PU for every $k \in \mathbb{N}$.
\end{lemma}

\begin{proof}
    \uses{Matrix.IsTotallyUnimodular,Matrix.IsPartiallyUnimodular}
    % \lean
    \leanok
    This follows from Definitions~\ref{Matrix.IsTotallyUnimodular} and~\ref{Matrix.IsPartiallyUnimodular}.
\end{proof}

\begin{definition}
    \label{Matrix.fromBlocks}
    \uses{Matrix}
    \leanok
    Matrix made of 4 blocks (2x2).
\end{definition}

\section{Pivoting}

% Long Tableau Pivot

\begin{definition}
    \label{Matrix.longTableauPivot}
    \uses{Matrix}
    % \lean{Matrix.longTableauPivot}
    \leanok
    Let $A \in R^{X \times Y}$ be a matrix and let $(x, y) \in X \times Y$ be such that $A (x, y) \neq 0$. A long tableau pivot in $A$ on $(x, y)$ is the operation that maps $A$ to the matrix $A'$ where
    \[
        \forall i \in X, \ \forall j \in Y, \ A' (i, j) = \begin{cases}
            \frac{A (i, j)}{A (x, y)}, & \text{ if } i = x, \\
            A (i, j) - \frac{A (i, y) \cdot A (x, j)}{A (x, y)}, & \text{ if } i \neq x.
        \end{cases}
    \]
\end{definition}

\begin{lemma}
    \label{Matrix.IsTotallyUnimodular.longTableauPivot}
    \uses{Matrix.IsTotallyUnimodular,Matrix.longTableauPivot}
    % \lean{Matrix.IsTotallyUnimodular.longTableauPivot}
    \leanok
    Let $A \in \mathbb{Q}^{X \times Y}$ be a TU matrix and let $(x, y) \in X \times Y$ be such that $A (x, y) \neq 0$. Then performing the long tableau pivot in $A$ on $(x, y)$ yields a TU matrix.
\end{lemma}

\begin{proof}
    \leanok
    \SeeLean
\end{proof}


% Short Tableau Pivot

\begin{definition}
    \label{Matrix.shortTableauPivot}
    \uses{Matrix.longTableauPivot}
    % \lean{Matrix.shortTableauPivot}
    \leanok
    Let $A \in R^{X \times Y}$ be a matrix and let $(x, y) \in X \times Y$ be such that $A (x, y) \neq 0$. Perform the following sequence of operations.
    \begin{enumerate}
        \item Adjoin the identity matrix $1 \in R^{X \times X}$ to $A$, resulting in the matrix $B = \begin{bmatrix} 1 & A \end{bmatrix} \in R^{X \times (X \oplus Y)}$.
        \item Perform a long tableau pivot in $B$ on $(x, y)$, and let $C$ denote the result.
        \item Swap columns $x$ and $y$ in $C$, and let $D$ be the resulting matrix.
        \item Finally, remove columns indexed by $X$ from $D$, and let $A'$ be the resulting matrix.
    \end{enumerate}
    A short tableau pivot in $A$ on $(x, y)$ is the operation that maps $A$ to the matrix $A'$ defined above.
\end{definition}

\begin{lemma}
    \label{Matrix.shortTableauPivot_eq}
    \uses{Matrix.shortTableauPivot}
    % \lean{Matrix.shortTableauPivot_eq}
    \leanok
    Let $A \in R^{X \times Y}$ be a matrix and let $(x, y) \in X \times Y$ be such that $A (x, y) \neq 0$. Then the short tableau pivot in $A$ on $(x, y)$ maps $A$ to $A'$ with
    \[
        \forall i \in X, \ \forall j \in Y, \ A' (i, j) = \begin{cases}
            \frac{1}{A (x, y)}, & \text{ if } i = x \text{ and } j = y, \\
            \frac{A (x, j)}{A (x, y)}, & \text{ if } i = x \text{ and } j \neq y, \\
            -\frac{A (i, j)}{A (x, y)}, & \text{ if } i \neq x \text{ and } j = y, \\
            A (i, j) - \frac{A (i, y) \cdot A (x, j)}{A (x, y)}, & \text{ if } i \neq x \text{ and } j \neq y.
        \end{cases}
    \]
\end{lemma}

\begin{proof}
    \leanok
    Follows by direct calculation.
\end{proof}

\begin{lemma}
    \label{Matrix.shortTableauPivot_zero}
    \uses{Matrix.shortTableauPivot}
    % \lean{}
    \leanok
    Let $B = \begin{bmatrix} B_{11} & 0 \\ B_{21} & B_{22} \end{bmatrix} \in \mathbb{Q}^{\{X_{1} \cup X_{2}\} \times \{Y_{1} \times Y_{2}\}}$. Let $B' = \begin{bmatrix} B_{11}' & B_{12}' \\ B_{21}' & B_{22}' \end{bmatrix}$ be the result of performing a short tableau pivot on $(x, y) \in X_{1} \times Y_{1}$ in $B$. Then $B_{12}' = 0$, $B_{22}' = B_{22}$, and $\begin{bmatrix} B_{11}' \\ B_{21}' \end{bmatrix}$ is the matrix resulting from performing a short tableau pivot on $(x, y)$ in $\begin{bmatrix} B_{11} \\ B_{21} \end{bmatrix}$.
\end{lemma}

\begin{proof}
    \leanok
    This follows by a direct calculation. Indeed, because of the $0$ block in $B$, $B_{12}$ and $B_{22}$ remain unchanged, and since $\begin{bmatrix} B_{11} \\ B_{21} \end{bmatrix}$ is a submatrix of $B$ containing the pivot element, performing a short tableau pivot in it is equivalent to performing a short tableau pivot in $B$ and then taking the corresponding submatrix.
\end{proof}

\begin{lemma}
    \label{shortTableauPivot_submatrix_det_abs_eq_div}
    \uses{Matrix.shortTableauPivot}
    % \lean{}
    \leanok
    Let $k \in \mathbb{N}$, let $A \in \mathbb{Q}^{k \times k}$, and let $A'$ be the result of performing a short tableau pivot in $A$ on $(x, y)$ with $x, y \in \{1, \dots, k\}$ such that $A (x, y) \neq 0$. Then $A'$ contains a submatrix $A''$ of size $(k - 1) \times (k - 1)$ with $|\det A''| = |\det A| / |A (x, y)|$.
\end{lemma}

\begin{proof}
    \leanok
    Let $X = \{1, \dots, k\} \setminus \{x\}$ and $Y = \{1, \dots, k\} \setminus \{y\}$, and let $A'' = A' (X, Y)$. Since $A''$ does not contain the pivot row or the pivot column, $\forall (i, j) \in X \times Y$ we have $A'' (i, j) = A (i, j) - \frac{A (i, y) \cdot A (x, j)}{A (x, y)}$. For $\forall j \in Y$, let $B_{j}$ be the matrix obtained from $A$ by removing row $x$ and column $j$, and let $B_{j}''$ be the matrix obtained from $A''$ by replacing column $j$ with $A (X, y)$ (i.e., the pivot column without the pivot element). The cofactor expansion along row $x$ in $A$ yields
    \[
        \det A = \sum_{j = 1}^{k} (-1)^{y + j} \cdot A (x, j) \cdot \det B_{j}.
    \]
    By reordering columns of every $B_{j}$ to match their order in $B_{j}''$, we get
    \[
        \det A = (-1)^{x + y} \cdot \left( A (x, y) \cdot \det A' - \sum_{j \in Y} A (x, j) \cdot \det B_{j}'' \right).
    \]
    By linearity of the determinant applied to $\det A''$, we have
    \[
        \det A'' = \det A' - \sum_{j \in Y} \frac{A (x, j)}{A (x, y)} \cdot \det B_{j}''
    \]
    Therefore, $|\det A''| = |\det A| / |A (x, y)|$.
\end{proof}

\begin{lemma}
    \label{Matrix.IsTotallyUnimodular.shortTableauPivot}
    \uses{Matrix.IsTotallyUnimodular,Matrix.shortTableauPivot}
    % \lean{Matrix.IsTotallyUnimodular.shortTableauPivot}
    \leanok
    Let $A \in \mathbb{Q}^{X \times Y}$ be a TU matrix and let $(x, y) \in X \times Y$ be such that $A (x, y) \neq 0$. Then performing the short tableau pivot in $A$ on $(x, y)$ yields a TU matrix.
\end{lemma}

\begin{proof}
    \uses{Matrix.IsTotallyUnimodular.longTableauPivot}
    \leanok
    \SeeLean
\end{proof}


\section{Vector Matroids}

\begin{definition}
    \label{Matroid}
    \leanok
    A matroid $M$ is a pair $(E, \mathcal{I})$ where $E$ is a (possibly infinite) set and $\mathcal I \in 2^E$ is such that:
    \begin{enumerate}
        \item $\emptyset \in \mathcal I$
        \item If $I \in \mathcal I$ and $J \subseteq I$, then $I \in \mathcal I$.
        \item If $I \in \mathcal I$ is not maximal (with respect to set inclusion) and $B \in \mathcal I$ is maximal,
            then there exists an $x \in B \setminus I$ such that $I \cup \{x\} \in \mathcal{I}$.
        \item If $X \subseteq E$ and $I \subseteq X$ is such that $I \in \mathcal I$, then there exists an $J \in \mathcal I$ with $I \subseteq J \subseteq X$
            that is maximal with respect to set inclusion.
    \end{enumerate}
    We call $E$ the grounnd set of $M$ and $\mathcal{I}$ the collection of independent sets in $M$.
\end{definition}

\begin{definition}
    \label{VectorMatroid}
    \uses{Matrix, Matroid}
    \leanok
    Let $R$ be a division ring, let $X$ and $Y$ be sets, and let $A \in R^{X \times Y}$ be a matrix. The vector matroid of $A$ is the matroid $M = (Y, \mathcal{I})$ where a set $I \subset Y$ is independent in $M$ if and only if the columns of $A$ indexed by $I$ are linearly independent.
\end{definition}

\begin{definition}
    \label{StandardRepr}
    \uses{VectorMatroid}
    % \lean{}
    \leanok
    Let $R$ be a division ring, let $X$ and $Y$ be disjoint sets, and let $S \in R^{X \times Y}$ be a matrix. Let $A = \begin{bmatrix} 1 & S \end{bmatrix} \in R^{X \times (X \cup Y)}$ be the matrix obtained from $S$ by adjoining the identity matrix as columns, and let $M$ be the vector matroid of $A$. Then $S$ is called the standard representation of $M$.
\end{definition}

\begin{lemma}
    \label{StandardRepr.toMatroid_isBase_X}
    \uses{StandardRepr}
    % \lean{}
    \leanok
    Let $S \in R^{X \times Y}$ be a standard representation of a vector matroid $M$. Then $X$ is a base in $M$.
\end{lemma}

\begin{proof}
    \leanok
    \SeeLean
\end{proof}

% Was removed from the project:

% \begin{lemma}
%     \label{lem:full_repr_to_std_repr}
%     \uses{VectorMatroid,StandardRepr}
%     % \lean{}
%     \leanok
%     Let $A \in \mathbb{Q}^{X \times Y}$ be a matrix, let $M$ be the vector matroid of $A$, and let $B$ be a base of $M$. Then there exists a standard representation matrix $S \in \mathbb{Q}^{B \times (Y \setminus B)}$ of $M$.
% \end{lemma}

% \begin{proof
%     \leanok
%     \SeeLean
% \end{proof}

\begin{lemma}
    \label{Matrix.fromRows_zero_reindex_toMatroid}
    \uses{VectorMatroid}
    % \lean{}
    \leanok
    Adding extra zero rows to a full representation matrix of a vector matroid does not change the matroid.
\end{lemma}

\begin{proof}
    \leanok
    \SeeLean
\end{proof}

\begin{lemma}
    \label{VectorMatroid.exists_standardRepr_isBase_isTotallyUnimodular}
    \uses{Matrix.IsTotallyUnimodular,VectorMatroid,StandardRepr}
    % \lean{}
    \leanok
    Let $A \in \mathbb{Q}^{X \times Y}$ be a TU matrix, let $M$ be the vector matroid of $A$, and let $B$ be a base of $M$. Then there exists a matrix $S \in \mathbb{Q}^{B \times (Y \setminus B)}$ such that $S$ is TU and $S$ is a standard representation of $M$.
\end{lemma}

\begin{proof}
    \uses{Matrix.IsTotallyUnimodular.longTableauPivot,Matrix.fromRows_zero_reindex_toMatroid}
    \leanok
    \SeeLean
\end{proof}

% Representation via support matrices

\begin{definition}
    \label{Matrix.support}
    \uses{Matrix}
    \leanok
    Let $R$ be a magma containing zero. The support of matrix $A \in R^{X \times Y}$ is $A^{\#} \in \{0, 1\}^{X \times Y}$ given by
    \[
        \forall i \in X, \ \forall j \in Y, \ A^{\#} (i, j) = \begin{cases}
            0, & \text{ if } A (i, j) = 0, \\
            1, & \text{ if } A (i, j) \neq 0.
        \end{cases}
    \]
\end{definition}

\begin{lemma}
    \label{Matrix.support_transpose}
    \uses{Matrix.support}
    % \lean{}
    \leanok
    Transpose of a support matrix is equal to a support of the transposed matrix.
\end{lemma}

\begin{proof}
    \leanok
    Definitional equality.
\end{proof}

\begin{lemma}
    \label{Matrix.support_submatrix}
    \uses{Matrix.support}
    % \lean{}
    \leanok
    Submatrix of a support matrix is equal to a support matrix of the submatrix.
\end{lemma}

\begin{proof}
    \leanok
    Definitional equality.
\end{proof}

\begin{lemma}
    \label{Matrix.support_Z2}
    \uses{Matrix.support}
    % \lean{}
    \leanok
    If $A$ is a matrix over $\mathbb{Z}_{2}$, then $A^{\#} = A$.
\end{lemma}

\begin{proof}
    \leanok
    Check elementwise equality.
\end{proof}

\begin{lemma}
    \label{support_eq_support_of_same_matroid_same_X}
    \uses{Matrix.support,StandardRepr}
    % \lean{}
    \leanok
    If two standard representation matrices of the same matroid have the same base, then they have the same support.
\end{lemma}

\begin{proof}
    \leanok
    \SeeLean
\end{proof}

\begin{lemma}
    \label{Matrix.isUnit_iff_isUnit_det}
    \uses{Matrix.det}
    % \lean{}
    \leanok
    A square matrix is invertible iff its determinant is invertible.
\end{lemma}

\begin{proof}
    \leanok
    This result is proved in Mathlib.
\end{proof}

\begin{lemma}
    \label{Matrix.IsTotallyUnimodular.linearIndependent_iff_support_linearIndependent_of_finite_of_finite}
    \uses{Matrix.IsTotallyUnimodular,Matrix.support}
    % \lean{}
    \leanok
    Let $A$ be a rational TU matrix with finite number of rows and finite number of columns.
    Its rows are linearly independent iff the rows of its support matrix are linearly independent.
\end{lemma}

\begin{proof}
    \uses{Matrix.support_submatrix,Matrix.isUnit_iff_isUnit_det}
    \leanok
    \SeeLean
\end{proof}

\begin{lemma}
    \label{Matrix.IsTotallyUnimodular.linearIndependent_iff_support_linearIndependent_of_finite}
    \uses{Matrix.IsTotallyUnimodular,Matrix.support}
    % \lean{}
    \leanok
    Let $A$ be a rational TU matrix with finite number of rows.
    Its rows are linearly independent iff the rows of its support matrix are linearly independent.
\end{lemma}

\begin{proof}
    \uses{Matrix.IsTotallyUnimodular.linearIndependent_iff_support_linearIndependent_of_finite_of_finite}
    \leanok
    \SeeLean
\end{proof}

\begin{lemma}
    \label{Matrix.IsTotallyUnimodular.linearIndependent_iff_support_linearIndependent}
    \uses{Matrix.IsTotallyUnimodular,Matrix.support}
    % \lean{}
    \leanok
    Let $A$ be a rational TU matrix.
    Its rows are linearly independent iff the rows of its support matrix are linearly independent.
\end{lemma}

\begin{proof}
    \uses{Matrix.IsTotallyUnimodular.linearIndependent_iff_support_linearIndependent_of_finite}
    \leanok
    \SeeLean
\end{proof}

\begin{lemma}
    \label{Matrix.IsTotallyUnimodular.toMatroid_eq_support_toMatroid}
    \uses{Matrix.IsTotallyUnimodular,Matrix.support,StandardRepr}
    % \lean{}
    \leanok
    Let $A$ be a TU matrix.
    \begin{enumerate}
        \item If a matroid is represented by $A$, then it is also represented by $A^{\#}$.
        \item If a matroid is represented by $A^{\#}$, then it is also represented by $A$.
    \end{enumerate}
\end{lemma}

\begin{proof}
    \uses{Matrix.support_transpose,Matrix.support_submatrix,Matrix.IsTotallyUnimodular.linearIndependent_iff_support_linearIndependent}
    \leanok
    \SeeLean
\end{proof}


\section{Regular Matroids}

\begin{definition}
    \label{Matroid.IsRegular}
    \uses{Matroid,VectorMatroid,Matrix.IsTotallyUnimodular}
    % \lean{}
    \leanok
    A matroid $M$ is regular if there exists a TU matrix $A \in \mathbb{Q}^{X \times Y}$ such that $M$ is a vector matroid of $A$.
\end{definition}

\begin{definition}
    \label{Matrix.IsTuSigningOf}
    \uses{Matrix.IsTotallyUnimodular}
    % \lean{}
    \leanok
    We say that $A' \in \mathbb{Q}^{X \times Y}$ is a TU signing of $A \in \mathbb{Z}_{2}^{X \times Y}$ if $A'$ is TU and
    \[
        \forall i \in X, \ \forall j \in Y, \ |A' (i, j)| = A (i, j).
    \]
\end{definition}

% Possible to include here: Matroid.IsRegular.isBinary
% \uses{Matroid.IsRegular,Matrix.support,Matrix.IsTotallyUnimodular.toMatroid_eq_support_toMatroid}
% \leanok

\begin{lemma}
    \label{StandardRepr.toMatroid_isRegular_iff_hasTuSigning}
    \uses{StandardRepr,Matroid.IsRegular,Matrix.IsTuSigningOf}
    % \lean{}
    \leanok
    Let $B \in \mathbb{Z}_{2}^{X \times Y}$ be a standard representation matrix of a matroid $M$. Then $M$ is regular if and only if $B$ has a TU signing.
\end{lemma}

\begin{proof}
    \uses{Matroid.IsRegular,Matrix.IsTuSigningOf,StandardRepr.toMatroid_isBase_X,VectorMatroid.exists_standardRepr_isBase_isTotallyUnimodular,support_eq_support_of_same_matroid_same_X,Matrix.IsTotallyUnimodular.toMatroid_eq_support_toMatroid, Matrix.support_Z2}
    \leanok
    Suppose that $M$ is regular. By Definition~\ref{Matroid.IsRegular}, there exists a TU matrix $A \in \mathbb{Q}^{X \times Y}$ such that $M$ is a vector matroid of $A$. By Lemma~\ref{StandardRepr.toMatroid_isBase_X}, $X$ (the row set of $B$) is a base of $M$. By Lemma~\ref{VectorMatroid.exists_standardRepr_isBase_isTotallyUnimodular}, $A$ can be converted into a standard representation matrix $B' \in \mathbb{Q}^{X \times Y}$ of $M$ such that $B'$ is also TU. Since $B'$ and $B$ are both standard representations of $M$, by Lemma~\ref{support_eq_support_of_same_matroid_same_X} the support matrices $(B')^{\#}$ and $B^{\#}$ are the same. Lemma \ref{Matrix.support_Z2} gives $B^{\#} = B$. Thus, $B'$ is TU and $(B')^{\#} = B$, so $B'$ is a TU signing of $B$.

    Suppose that $B$ has a TU signing $B' \in \mathbb{Q}^{X \times Y}$. Then $A = [1 \mid B']$ is TU, as it is obtained from $B'$ by adjoining the identity matrix. Moreover, by Lemma~\ref{Matrix.IsTotallyUnimodular.toMatroid_eq_support_toMatroid}, $A$ represents the same matroid as $A^{\#} = [1 \mid B]$, which is $M$. Thus, $A$ is a TU matrix representing $M$, so $M$ is regular.
\end{proof}
